"""AI ì±„íŒ… ì„œë¹„ìŠ¤"""

from typing import List, Dict, Optional
from openai import OpenAI
from app.config import settings
from app.utils.prompts import CHAT_SYSTEM_PROMPT
import json
import logging

logger = logging.getLogger(__name__)


class ChatService:
    """AIì™€ ëŒ€í™”í•˜ë©° ì¹´ë“œë‰´ìŠ¤ ì„¹ì…˜ì„ ìˆ˜ì •í•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    def __init__(self, model: str = None):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = model or settings.OPENAI_MODEL
    
    def process_chat_message(
        self,
        user_message: str,
        current_sections: List[Dict],
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict:
        """
        ì‚¬ìš©ìì˜ ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ì„¹ì…˜ ìˆ˜ì • ì œì•ˆ
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€ ("ë‘ ë²ˆì§¸ ì¹´ë“œ ë” ê°„ê²°í•˜ê²Œ í•´ì¤˜")
            current_sections: í˜„ì¬ ì¹´ë“œ ì„¹ì…˜ ìƒíƒœ
            conversation_history: ì´ì „ ëŒ€í™” ì´ë ¥
            
        Returns:
            {
                'ai_response': str,              # AIì˜ ì‘ë‹µ ë©”ì‹œì§€
                'updated_sections': List[Dict],  # ìˆ˜ì •ëœ ì„¹ì…˜ (ìˆì„ ê²½ìš°)
                'action_taken': str              # ìˆ˜í–‰í•œ ì‘ì—… ('modify', 'reorder', 'none')
            }
        """
        logger.info(f"Processing chat message: {user_message}")
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        messages = [
            {"role": "system", "content": CHAT_SYSTEM_PROMPT}
        ]
        
        # ì´ì „ ëŒ€í™” ì´ë ¥ ì¶”ê°€ (ìµœê·¼ 5ê°œë§Œ)
        if conversation_history:
            messages.extend(conversation_history[-5:])
        
        # í˜„ì¬ ì„¹ì…˜ ì •ë³´ í¬í•¨
        sections_context = self._format_sections_for_context(current_sections)
        messages.append({
            "role": "system",
            "content": f"í˜„ì¬ ì¹´ë“œ ì„¹ì…˜ ìƒíƒœ:\n{sections_context}"
        })
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        try:
            # GPT í˜¸ì¶œ (Function Calling ì‚¬ìš©)
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000,
                functions=[  # Function callingìœ¼ë¡œ ì„¹ì…˜ ìˆ˜ì • ëª…ë ¹ êµ¬ì¡°í™”
                    {
                        "name": "modify_section",
                        "description": "íŠ¹ì • ì¹´ë“œ ì„¹ì…˜ì˜ ë‚´ìš©ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "section_index": {
                                    "type": "integer",
                                    "description": "ìˆ˜ì •í•  ì„¹ì…˜ì˜ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)"
                                },
                                "new_title": {
                                    "type": "string",
                                    "description": "ìƒˆë¡œìš´ ì œëª© (ë³€ê²½í•˜ì§€ ì•Šìœ¼ë©´ ìƒëµ ê°€ëŠ¥)"
                                },
                                "new_content": {
                                    "type": "string",
                                    "description": "ìƒˆë¡œìš´ ë‚´ìš©"
                                }
                            },
                            "required": ["section_index"]
                        }
                    },
                    {
                        "name": "reorder_sections",
                        "description": "ì¹´ë“œ ì„¹ì…˜ì˜ ìˆœì„œë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "new_order": {
                                    "type": "array",
                                    "items": {"type": "integer"},
                                    "description": "ìƒˆë¡œìš´ ìˆœì„œ ë°°ì—´ (ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸)"
                                }
                            },
                            "required": ["new_order"]
                        }
                    },
                    {
                        "name": "modify_all_content",
                        "description": "ëª¨ë“  ì¹´ë“œì˜ ë‚´ìš©ì„ ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ì²­ì— ë”°ë¼ ìˆ˜ì •í•©ë‹ˆë‹¤. ì¡´ëŒ“ë§/ë°˜ë§ ë³€ê²½, í†¤ ë³€ê²½, ê¸¸ì´ ì¡°ì ˆ, ìŠ¤íƒ€ì¼ ë³€ê²½, ì´ëª¨ì§€ ì¶”ê°€ ë“± ëª¨ë“  ì „ì²´ ìˆ˜ì • ìš”ì²­ì— ì‚¬ìš©í•©ë‹ˆë‹¤.",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "instruction": {
                                    "type": "string",
                                    "description": "ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ì²­ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬ (ì˜ˆ: 'ì¡´ëŒ“ë§ë¡œ ë°”ê¿”ì¤˜', 'ë” ì „ë¬¸ì ìœ¼ë¡œ ìˆ˜ì •í•´ì¤˜', 'ì´ëª¨ì§€ ì¶”ê°€í•´ì¤˜', 'ê°„ê²°í•˜ê²Œ ì¤„ì—¬ì¤˜' ë“±)"
                                }
                            },
                            "required": ["instruction"]
                        }
                    }
                ]
            )
            
            # ì‘ë‹µ ì²˜ë¦¬
            choice = response.choices[0]
            
            if choice.message.function_call:
                # Function callì´ ìˆìœ¼ë©´ ì„¹ì…˜ ìˆ˜ì • ìˆ˜í–‰
                return self._handle_function_call(
                    choice.message.function_call,
                    current_sections
                )
            else:
                # ì¼ë°˜ ëŒ€í™” ì‘ë‹µ
                return {
                    'ai_response': choice.message.content or "ì•Œê² ìŠµë‹ˆë‹¤.",
                    'updated_sections': None,
                    'action_taken': 'none'
                }
                
        except Exception as e:
            logger.error(f"Chat processing failed: {str(e)}")
            return {
                'ai_response': f"ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'updated_sections': None,
                'action_taken': 'none'
            }
    
    def _format_sections_for_context(self, sections: List[Dict]) -> str:
        """
        ì„¹ì…˜ ì •ë³´ë¥¼ GPTê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·
        
        Args:
            sections: ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í¬ë§·ëœ ë¬¸ìì—´
        """
        formatted = []
        for idx, section in enumerate(sections):
            formatted.append(
                f"ì¹´ë“œ {idx + 1} ({section.get('type', 'content')}):\n"
                f"  ì œëª©: {section.get('title', 'N/A')}\n"
                f"  ë‚´ìš©: {section.get('content', '')[:100]}..."
            )
        return '\n\n'.join(formatted)
    
    def _handle_function_call(self, function_call, current_sections: List[Dict]) -> Dict:
        """
        Function call ì²˜ë¦¬í•˜ì—¬ ì„¹ì…˜ ìˆ˜ì •
        
        Args:
            function_call: OpenAI function call ê°ì²´
            current_sections: í˜„ì¬ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ìˆ˜ì • ê²°ê³¼
        """
        function_name = function_call.name
        arguments = json.loads(function_call.arguments)
        
        logger.info(f"Function call: {function_name} with args: {arguments}")
        
        updated_sections = [section.copy() for section in current_sections]
        
        if function_name == "modify_section":
            idx = arguments.get('section_index', 0)
            
            if 0 <= idx < len(updated_sections):
                if 'new_title' in arguments and arguments['new_title']:
                    updated_sections[idx]['title'] = arguments['new_title']
                if 'new_content' in arguments and arguments['new_content']:
                    updated_sections[idx]['content'] = arguments['new_content']
                
                return {
                    'ai_response': f"ì¹´ë“œ {idx + 1}ì˜ ë‚´ìš©ì„ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.",
                    'updated_sections': updated_sections,
                    'action_taken': 'modify'
                }
            else:
                return {
                    'ai_response': f"ì¹´ë“œ {idx + 1}ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    'updated_sections': None,
                    'action_taken': 'none'
                }
        
        elif function_name == "reorder_sections":
            new_order = arguments.get('new_order', [])
            
            if len(new_order) == len(current_sections):
                updated_sections = [current_sections[i] for i in new_order]
                # order í•„ë“œ ì—…ë°ì´íŠ¸
                for idx, section in enumerate(updated_sections):
                    section['order'] = idx
                
                return {
                    'ai_response': "ì¹´ë“œ ìˆœì„œë¥¼ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.",
                    'updated_sections': updated_sections,
                    'action_taken': 'reorder'
                }
            else:
                return {
                    'ai_response': "ìˆœì„œ ë³€ê²½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ì¸ë±ìŠ¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                    'updated_sections': None,
                    'action_taken': 'none'
                }
        
        elif function_name == "modify_all_content":
            instruction = arguments.get('instruction', '')
            
            # AIë¡œ ì „ì²´ ì¹´ë“œ ë‚´ìš© ìˆ˜ì •
            updated_sections = self._modify_all_with_ai(
                current_sections,
                instruction
            )
            
            return {
                'ai_response': f"âœ… ëª¨ë“  ì¹´ë“œë¥¼ '{instruction}' ìš”ì²­ì— ë”°ë¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.",
                'updated_sections': updated_sections,
                'action_taken': 'modify'
            }
        
        return {
            'ai_response': "ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            'updated_sections': None,
            'action_taken': 'none'
        }
    
    def _modify_all_with_ai(
        self, 
        current_sections: List[Dict], 
        instruction: str
    ) -> List[Dict]:
        """
        AIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì„¹ì…˜ì„ ì¼ê´„ ìˆ˜ì •
        
        Args:
            current_sections: í˜„ì¬ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
            instruction: ì‚¬ìš©ìì˜ ìì—°ì–´ ìˆ˜ì • ìš”ì²­
            
        Returns:
            ìˆ˜ì •ëœ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # í˜„ì¬ ì„¹ì…˜ì„ JSON í˜•íƒœë¡œ í¬ë§·
            sections_json = json.dumps([{
                'type': s.get('type', 'content'),
                'title': s.get('title', ''),
                'content': s.get('content', '')
            } for s in current_sections], ensure_ascii=False, indent=2)
            
            prompt = f"""
ì‚¬ìš©ì ìš”ì²­: "{instruction}"

ìœ„ ìš”ì²­ì— ë”°ë¼ ì•„ë˜ ì¹´ë“œë‰´ìŠ¤ì˜ ëª¨ë“  ì„¹ì…˜ì„ **ë°˜ë“œì‹œ ìˆ˜ì •**í•´ì£¼ì„¸ìš”.

í˜„ì¬ ì„¹ì…˜:
{sections_json}

ìˆ˜ì • ì§€ì¹¨:
1. **ì¤‘ìš”**: ì‚¬ìš©ì ìš”ì²­ì„ ì •í™•íˆ ë°˜ì˜í•˜ì—¬ ë‚´ìš©ì„ **ë°˜ë“œì‹œ ë³€ê²½**í•´ì•¼ í•©ë‹ˆë‹¤
2. ì¹´ë“œì˜ ê°œìˆ˜ëŠ” {len(current_sections)}ê°œë¡œ ìœ ì§€
3. ê° ì¹´ë“œì˜ typeì€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”
4. titleê³¼ contentë¥¼ ìš”ì²­ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”

ì˜ˆì‹œ:
- "ì¡´ëŒ“ë§ë¡œ ë°”ê¿”ì¤˜" â†’ "í•©ë‹ˆë‹¤", "~ì„¸ìš”" ë“± ì¡´ëŒ“ë§ ì‚¬ìš©
- "ë°˜ë§ë¡œ ë°”ê¿”ì¤˜" â†’ "í•œë‹¤", "~ì•¼" ë“± ë°˜ë§ ì‚¬ìš©
- "ì „ë¬¸ì ìœ¼ë¡œ" â†’ ì „ë¬¸ ìš©ì–´, ê²©ì‹ìˆëŠ” í‘œí˜„ ì‚¬ìš©
- "ì¹œê·¼í•˜ê²Œ" â†’ í¸ì•ˆí•œ ë§íˆ¬, ê³µê°í•˜ëŠ” í‘œí˜„ ì‚¬ìš©
- "ê°„ê²°í•˜ê²Œ" â†’ í•µì‹¬ë§Œ ë‚¨ê¸°ê³  ì¶•ì•½
- "ìƒì„¸í•˜ê²Œ" â†’ ì„¤ëª…ê³¼ ì˜ˆì‹œ ì¶”ê°€
- "ì´ëª¨ì§€ ì¶”ê°€" â†’ ì ì ˆí•œ ì´ëª¨ì§€(ğŸ‰âœ¨ğŸ’¡ğŸ“Œ ë“±) í™œìš©
- "ìŠ¤í† ë¦¬í…”ë§" â†’ ì´ì•¼ê¸° í˜•ì‹ìœ¼ë¡œ ì¬êµ¬ì„±
- "ì§ˆë¬¸ í˜•ì‹" â†’ ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” êµ¬ì¡°

**ë°˜ë“œì‹œ** ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

{{
  "sections": [
    {{"type": "title", "title": "ìˆ˜ì •ëœ ì œëª©", "content": "ìˆ˜ì •ëœ ë‚´ìš©"}},
    {{"type": "content", "title": "ìˆ˜ì •ëœ ì œëª©", "content": "ìˆ˜ì •ëœ ë‚´ìš©"}},
    ...
  ]
}}

âš ï¸ ì£¼ì˜: ì›ë³¸ê³¼ ë™ì¼í•œ ë‚´ìš©ì„ ë°˜í™˜í•˜ì§€ ë§ˆì„¸ìš”! ë°˜ë“œì‹œ ìš”ì²­ì— ë”°ë¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤!
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹´ë“œë‰´ìŠ¤ ë‚´ìš©ì„ ìˆ˜ì •í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì •í™•íˆ ë°˜ì˜í•˜ì—¬ ë‚´ìš©ì„ ë°˜ë“œì‹œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤. í•­ìƒ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,  # ì°½ì˜ì„±ì„ ìœ„í•´ ì•½ê°„ ë†’ì„
                max_tokens=2000
            )
            
            response_text = response.choices[0].message.content
            
            # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0]
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0]
            
            result = json.loads(response_text.strip())
            modified_sections = result.get('sections', [])
            
            # ê¸°ì¡´ ì„¹ì…˜ì˜ ë©”íƒ€ë°ì´í„° ìœ ì§€í•˜ë©´ì„œ ë‚´ìš©ë§Œ ì—…ë°ì´íŠ¸
            updated_sections = []
            for idx, (original, modified) in enumerate(zip(current_sections, modified_sections)):
                updated_section = original.copy()
                updated_section['title'] = modified.get('title', original.get('title', ''))
                updated_section['content'] = modified.get('content', original.get('content', ''))
                updated_section['order'] = idx
                updated_sections.append(updated_section)
            
            return updated_sections
            
        except Exception as e:
            logger.error(f"Failed to modify all sections: {str(e)}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
            return current_sections

